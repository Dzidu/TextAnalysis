print(i)
}
## filtrujemy o wiadomości z nagłówkiem 7, czyli tylko artykuły.
article_lin <- article_links %>%
filter(str_sub(link, end = 42) == "https://wiadomosci.gazeta.pl/wiadomosci/7,")
rm(article_links_tmp, i)
webpage <- read_html(encoding = "ISO_8859-2", 'https://wiadomosci.gazeta.pl/wiadomosci/7,114884,26415647,senat-nie-przyspieszy-posiedzenia-w-sprawie-ustawy-covidowej.html')
webpage
results <- webpage %>% html_nodes(".short-desc")
results
safe_read_html <- safely(read_html)
get_article <- function(art_url) {
# próbujemy pobrać stronę
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
# jeśli się nie udało - wychodzimy z pustą tabelką
if(is.null(page$result)) {
return(tibble())
}
# udało się - wynik mamy w $result
page <- page$result
# autor tekstu
author <- page %>% html_node('span.article_author') %>% html_text() %>% trimws()
# data publikacji
date <- page %>% html_node("time") %>% html_text() %>% trimws() %>% dmy_hm()
# tytuł tekstu
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
# lead
lead <- page %>% html_node("div#gazeta_article_lead") %>% html_text() %>% trimws()
# pełna treść artykułu
body <- page %>% html_node("div#gazeta_article_body") %>% html_text() %>% trimws()
# pakujemy to w 1-wierszowa tabele
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
## i pobieramy zawartość tekstu
articles <- article_lin %>%
# działaj wierszami
rowwise() %>%
# dla każdego wiersza wywołaj funkcję get_article() z parametrem wziętym z kolumny "link"
do(get_article(.$link)) %>%
# złącz wszystkie otrzymane rezultaty
bind_rows() %>%
ungroup()
getwd()
setwd('D:/Mat disc/R/CDV - Text mining/Analiza_wiad')
## i zapis lokalny, żeby nie czekać tyle
saveRDS(articles, file = "articles_full.RDS")
library(tidyverse)
library(rvest)
library(stringr)
library(lubridate)
library(purrr)
library(dplyr, warn.conflicts = T)
library(RSelenium)
base_url_pt1 <- "https://cryptonews.net/?page="
n_index_pages <- 25
get_article_list_from_page <- function(page_no) {
page_url <- paste0(base_url_pt1, page_no)
page <- read_html(page_url)
links <- page %>%
html_node("section") %>%
html_nodes("div.desc.col-xs")
articles_tmp <- tibble(url=paste0("https://cryptonews.net",link = links %>% html_node("a") %>% html_attr("href")),
title =  links %>% html_node("a") %>% html_text())
return(articles_tmp)
}
article_links <- tibble()
for(i in 25:n_index_pages) {
article_links_tmp <- get_article_list_from_page(i)
article_links <- bind_rows(article_links, article_links_tmp)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
print(i)
}
rm(article_links_tmp, i)
webpage <- read_html(encoding = "ISO_8859-2", 'https://cryptonews.net/news/other/21113274/')
webpage
results <- webpage %>% html_nodes(".short-desc")
results
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_nodes("p") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
safe_read_html <- safely(read_html)
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_nodes("p") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
library(tidyverse)
library(rvest)
library(stringr)
library(lubridate)
library(purrr)
library(dplyr, warn.conflicts = T)
library(RSelenium)
base_url_pt1 <- "https://cryptonews.net/?page="
n_index_pages <- 25
get_article_list_from_page <- function(page_no) {
page_url <- paste0(base_url_pt1, page_no)
page <- read_html(page_url)
links <- page %>%
html_node("section") %>%
html_nodes("div.desc.col-xs")
articles_tmp <- tibble(url=paste0("https://cryptonews.net",link = links %>% html_node("a") %>% html_attr("href")),
title =  links %>% html_node("a") %>% html_text())
return(articles_tmp)
}
article_links <- tibble()
for(i in 25:n_index_pages) {
article_links_tmp <- get_article_list_from_page(i)
article_links <- bind_rows(article_links, article_links_tmp)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
print(i)
}
rm(article_links_tmp, i)
webpage <- read_html(encoding = "ISO_8859-2", 'https://cryptonews.net/news/other/21113274/')
webpage
results <- webpage %>% html_nodes(".short-desc")
results
safe_read_html <- safely(read_html)
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_nodes("p") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
View(article_links)
articles_tmp <- tibble(link=paste0("https://cryptonews.net", links %>% html_node("a") %>% html_attr("href")),
title =  links %>% html_node("a") %>% html_text())
get_article_list_from_page <- function(page_no) {
page_url <- paste0(base_url_pt1, page_no)
page <- read_html(page_url)
links <- page %>%
html_node("section") %>%
html_nodes("div.desc.col-xs")
articles_tmp <- tibble(link=paste0("https://cryptonews.net",url = links %>% html_node("a") %>% html_attr("href")),
title =  links %>% html_node("a") %>% html_text())
return(articles_tmp)
}
article_links <- tibble()
for(i in 25:n_index_pages) {
article_links_tmp <- get_article_list_from_page(i)
article_links <- bind_rows(article_links, article_links_tmp)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
print(i)
}
rm(article_links_tmp, i)
webpage <- read_html(encoding = "ISO_8859-2", 'https://cryptonews.net/news/other/21113274/')
webpage
results <- webpage %>% html_nodes(".short-desc")
results
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_nodes("p") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
View(articles)
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_node("div.news-item detail content_text") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
library(tidyverse)
library(rvest)
library(stringr)
library(lubridate)
library(purrr)
library(dplyr, warn.conflicts = T)
library(RSelenium)
base_url_pt1 <- "https://cryptonews.net/?page="
n_index_pages <- 25
get_article_list_from_page <- function(page_no) {
page_url <- paste0(base_url_pt1, page_no)
page <- read_html(page_url)
links <- page %>%
html_node("section") %>%
html_nodes("div.desc.col-xs")
articles_tmp <- tibble(link=paste0("https://cryptonews.net",url = links %>% html_node("a") %>% html_attr("href")),
title =  links %>% html_node("a") %>% html_text())
return(articles_tmp)
}
article_links <- tibble()
for(i in 25:n_index_pages) {
article_links_tmp <- get_article_list_from_page(i)
article_links <- bind_rows(article_links, article_links_tmp)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
print(i)
}
rm(article_links_tmp, i)
webpage <- read_html(encoding = "ISO_8859-2", 'https://cryptonews.net/news/other/21113274/')
webpage
results <- webpage %>% html_nodes(".short-desc")
results
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_node("div.news-item detail content_text") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
safe_read_html <- safely(read_html)
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_node("div.news-item detail content_text") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
View(articles)
library(tidyverse)
library(rvest)
library(stringr)
library(lubridate)
library(purrr)
library(dplyr, warn.conflicts = T)
library(RSelenium)
base_url_pt1 <- "https://cryptonews.net/?page="
n_index_pages <- 25
get_article_list_from_page <- function(page_no) {
page_url <- paste0(base_url_pt1, page_no)
page <- read_html(page_url)
links <- page %>%
html_node("section") %>%
html_nodes("div.desc.col-xs")
articles_tmp <- tibble(link=paste0("https://cryptonews.net",url = links %>% html_node("a") %>% html_attr("href")),
title =  links %>% html_node("a") %>% html_text())
return(articles_tmp)
}
article_links <- tibble()
for(i in 25:n_index_pages) {
article_links_tmp <- get_article_list_from_page(i)
article_links <- bind_rows(article_links, article_links_tmp)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
print(i)
}
rm(article_links_tmp, i)
webpage <- read_html(encoding = "ISO_8859-2", 'https://cryptonews.net/news/other/21113274/')
webpage
results <- webpage %>% html_nodes(".short-desc")
results
safe_read_html <- safely(read_html)
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_nodes("div.news-item detail content_text") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
View(articles)
base_url_pt1 <- "https://cryptonews.net/?page="
n_index_pages <- 25
get_article_list_from_page <- function(page_no) {
page_url <- paste0(base_url_pt1, page_no)
page <- read_html(page_url)
links <- page %>%
html_node("section") %>%
html_nodes("div.desc.col-xs")
articles_tmp <- tibble(link=paste0("https://cryptonews.net",url = links %>% html_node("a") %>% html_attr("href")),
title =  links %>% html_node("a") %>% html_text())
return(articles_tmp)
}
article_links <- tibble()
for(i in 25:n_index_pages) {
article_links_tmp <- get_article_list_from_page(i)
article_links <- bind_rows(article_links, article_links_tmp)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
print(i)
}
rm(article_links_tmp, i)
webpage <- read_html(encoding = "ISO_8859-2", 'https://cryptonews.net/news/other/21113274/')
webpage
results <- webpage %>% html_nodes(".short-desc")
results
safe_read_html <- safely(read_html)
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_nodes("div.news-item detail content_text") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
body <- page %>% html_nodes("p") %>% html_text() %>% trimws()
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_nodes("p") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_node("div.news-item.detail.content_text") html_node("p") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_node("div.news-item.detail.content_text") %>% html_node("p") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
get_article <- function(art_url) {
try(page <- safe_read_html(art_url, encoding = "iso-8859-2"))
if(is.null(page$result)) {
return(tibble())
}
page <- page$result
author <- page %>% html_node('span.source-host') %>% html_text() %>% trimws()
date <- page %>% html_node("span.datetime.flex.middle-xs") %>% html_text() %>% trimws() %>% dmy_hm()
title <- page %>%html_node("h1") %>% html_text() %>% trimws()
lead <- page %>% html_node("p") %>% html_text() %>% trimws()
body <- page %>% html_node("div.news-item.detail.content_text") %>% html_nodes("p") %>% html_text() %>% trimws()
article <- tibble(url = art_url, title = title, author = author, date = date, lead = lead, body = body,)
Sys.sleep(sample(seq(0.25, 1, 0.5), 1))
return(article)
}
articles <- article_links %>%
rowwise() %>%
do(get_article(.$link)) %>%
bind_rows() %>%
ungroup()
articles_grouped <- articles %>% group_by(url, title) %>%
articles_grouped <- articles %>% group_by(url, title)
articles_grouped <- articles %>% group_by(url, title) %>% summarise(across(body, sum))
articles_grouped <- articles %>% group_by(url, title) %>% summarise(across(body, mutate))
articles_grouped <- articles %>% group_by(url, title, author, date) %>% summarise(across(body, unite))
articles_grouped <- articles %>% group_by(url, title, author, date) %>% summarise(across(body, paste))
View(articles_grouped)
articles_grouped <- articles %>% group_by(url, title, author, date) %>% summarise(paste(body, sep = " "))
articles_grouped <- articles %>% group_by(url, title, author, date) %>% reframe(paste(body, sep = " "))
View(articles)
articles_grouped <- articles %>%
group_by(url,title,author,date,lead )
articles_grouped <- articles %>%
group_by(url,title,author,date,lead )  %>%
summarise(full_body = paste(body, collapse = " "))
length(unique(articles$url))
length(unique(articles$title))
length(unique(articles$author))
length(unique(articles$lead))
articles_grouped <- articles %>%
group_by(url )  %>%
summarise(full_body = paste(body, collapse = " "))
articles_grouped <- articles %>%
group_by(url,title,author,date,lead )  %>%
summarise(full_body = paste(body, collapse = " "))
load("C:/Users/Dom/Desktop/R/Rcw/R projekt/.RData")
load("C:/Users/Dom/Documents/GitHub/R projekt/.RData")
